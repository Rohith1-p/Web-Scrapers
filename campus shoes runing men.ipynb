{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0d286ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.campusshoes.com/collections/mens-sneakers\n",
      "2\n",
      "page --->  1\n",
      "url--> https://www.campusshoes.com/collections/mens-sneakers?page=1\n",
      "<Response [200]>\n",
      "sheet_flag False\n",
      "https://www.campusshoes.com/collections/mens-sports-shoes\n",
      "4\n",
      "page --->  1\n",
      "url--> https://www.campusshoes.com/collections/mens-sports-shoes?page=1\n",
      "<Response [200]>\n",
      "sheet_flag True\n",
      "page --->  2\n",
      "url--> https://www.campusshoes.com/collections/mens-sports-shoes?page=2\n",
      "<Response [200]>\n",
      "sheet_flag True\n",
      "page --->  3\n",
      "url--> https://www.campusshoes.com/collections/mens-sports-shoes?page=3\n",
      "<Response [200]>\n",
      "sheet_flag True\n"
     ]
    }
   ],
   "source": [
    "from scrapy.selector import Selector\n",
    "import requests\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------> Note <-------#\n",
    "\n",
    "#Create the a excel file with below file name here it is urls.xlsx with Fields \"Urls\" and \"Page Numbers\"\n",
    "\n",
    "\n",
    "# Here you have to give the page numbers below. I gave default 10 \n",
    "sheet_flag = False\n",
    "# format the date and time to include seconds\n",
    "timestamp = time.time()\n",
    "\n",
    "workbook_name =\"data\"+str(int(timestamp)) +'.xlsx'\n",
    "\n",
    "\n",
    "file_name = \"urls.xlsx\"\n",
    "\n",
    "df = pd.read_excel(file_name)\n",
    "urls = list(df['Urls'])\n",
    "page_nums = list(df['Page Numbers'])\n",
    "\n",
    "for j in range(len(urls)):\n",
    "    print(urls[j])\n",
    "    print(page_nums[j])\n",
    "\n",
    "    for i in range(1,page_nums[j]):\n",
    "        print(\"page ---> \",i)\n",
    "\n",
    "        # Here you have to change the url for which you need to scrape. You have to change part of the url before \"?page=\"\n",
    "        url = urls[j] +\"?page=\"+str(i)\n",
    "        print(\"url-->\",url)\n",
    "\n",
    "        response = requests.get(url)\n",
    "        print(response)\n",
    "\n",
    "        # Create a Selector from the response text\n",
    "        res = Selector(text=response.text)\n",
    "\n",
    "        # Extract raw data using CSS selectors\n",
    "        raw_data = res.css('div[data-section-id=\"template--15367256998119__main\"] div[class=\"block-inner-inner\"]')\n",
    "        data_dict = {'ProductTitle':[],'Price':[],'MRP':[], 'Colour':[], 'URL':[], 'Product_id':[], 'Size':[], 'Category':[]}\n",
    "    #     print(raw_data)\n",
    "        # Loop through the raw data and print the product titles\n",
    "        for data in raw_data:\n",
    "#             print(\"in data \")\n",
    "            product_title = data.css('div[class=\"product-info\"] div[class=\"product-block__title\"] h4::text' ).extract_first()\n",
    "            price= data.css('div[class=\"product-info\"] div[class=\"product-price\"] span[class=\"product-price__item product-price__amount product-price__amount--on-sale theme-money\"] ::text').extract_first()\n",
    "            Mrp_Price=data.css('div[class=\"product-info\"] div [class=\"product-price__item product-price__compare theme-money\"]::text').extract_first()\n",
    "            colour= data.css('div[class=\"product-info\"] div [class=\"product-block-options__item__text\"]::text').extract_first()\n",
    "            size1= data.css('div[class=\"product-info\"] div [class=\"product-block-options__item__text\"]::text').extract()\n",
    "            size11 = size1[1:]\n",
    "            size=str(size11)\n",
    "\n",
    "            link= data.css('div [class=\"product-link\"]::attr(href)').extract_first()\n",
    "            try:\n",
    "                Url= url.split('?')[0]+link\n",
    "            except:\n",
    "                Url = '-'\n",
    "            product_id=data.css('::attr(data-id)').extract_first()\n",
    "\n",
    "            try:\n",
    "                data_dict['ProductTitle'].append(product_title.strip())\n",
    "            except:\n",
    "                data_dict['ProductTitle'].append('-')\n",
    "            data_dict['Price'].append(price)\n",
    "            data_dict['MRP'].append(Mrp_Price)\n",
    "            data_dict['Colour'].append(colour)\n",
    "            data_dict['URL'].append(Url)\n",
    "            data_dict['Product_id'].append(product_id)\n",
    "            data_dict['Size'].append(size)\n",
    "\n",
    "            try:\n",
    "                category = ' '.join(url.split('/')[-1].split('?')[0].split('-'))\n",
    "            except:\n",
    "                category = '-'\n",
    "\n",
    "            data_dict['Category'].append(category)\n",
    "            \n",
    "            \n",
    "\n",
    "            # get the current date and time\n",
    "\n",
    "        \n",
    "\n",
    "        data_df = pd.DataFrame(data_dict)\n",
    "        columns = data_df.columns.to_list()    \n",
    "        df_values = data_df.values.tolist()\n",
    "        df_values.insert(0,columns)\n",
    "\n",
    "        print(\"sheet_flag\",sheet_flag)\n",
    "        if sheet_flag == False:\n",
    "\n",
    "            sheet_flag = True\n",
    "            wb = openpyxl.Workbook()\n",
    "            ws = wb.active\n",
    "            for row in df_values:\n",
    "                ws.append(row)\n",
    "                wb.save(workbook_name)\n",
    "\n",
    "            data_dict = {'ProductTitle':[],'Price':[],'MRP':[], 'Colour':[], 'URL':[], 'Product_id':[], 'Size':[],'Category':[]}\n",
    "\n",
    "\n",
    "        else:\n",
    "            df_values = data_df.values.tolist()\n",
    "            wb = load_workbook(workbook_name)\n",
    "            page = wb.active\n",
    "            for row in df_values:\n",
    "                #print(row)\n",
    "                page.append(row)\n",
    "                wb.save(filename=workbook_name)\n",
    "            data_dict = {'ProductTitle':[],'Price':[],'MRP':[], 'Colour':[], 'URL':[], 'Product_id':[], 'Size':[],'Category':[]}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae62593",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5c58c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8be0d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
